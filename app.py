import streamlit as st
import pandas as pd
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from dotenv import load_dotenv
from langchain_chroma import Chroma
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.chains import create_retrieval_chain
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.documents import Document
import os

# Ortam deÄŸiÅŸkenlerini yÃ¼kle (.env iÃ§indeki API anahtarÄ± iÃ§in)
load_dotenv()

# Streamlit baÅŸlÄ±k
st.title("ğŸ¬ Film Ã–neri Chatbotu (Gemini)")

# Excel veri kÃ¼mesini yÃ¼kle
df = pd.read_excel("film_chatbot_veri_seti.xlsx")

# Excel'deki text-intent verilerini Document yapÄ±sÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
docs = [
    Document(page_content=row['text'], metadata={"intent": row['intent']})
    for _, row in df.iterrows()
]

# Metinleri parÃ§alara ayÄ±r
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
split_docs = text_splitter.split_documents(docs)

# Embedding modeli (Gemini)
embedding_model = GoogleGenerativeAIEmbeddings(model="models/embedding-001")

# VektÃ¶r veritabanÄ± (Chroma ile)
vectorstore = Chroma.from_documents(
    documents=split_docs,
    embedding=embedding_model,
    persist_directory="./chroma_db_film"
)

# Retriever
retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 4})

# LLM (Gemini Pro)
llm = ChatGoogleGenerativeAI(
    model="models/gemini-1.5-flash-latest",
    temperature=0.1,
    max_tokens=500
)

# Sistem prompt'u
system_prompt = (
    "Sen bir film Ã¶neri asistanÄ±sÄ±n. KullanÄ±cÄ±nÄ±n niyetine gÃ¶re ona film Ã¶nerisinde bulunacaksÄ±n. "
    "AÅŸaÄŸÄ±da geÃ§miÅŸ sorgulardan alÄ±nan benzer Ã¶rnekler (context) yer almakta. "
    "EÄŸer kullanÄ±cÄ± ne tÃ¼r film istediÄŸini aÃ§Ä±k belirtmiÅŸse buna gÃ¶re Ã¶neride bulun. "
    "EÄŸer belirli bir oyuncu veya duygu belirtmiÅŸse, buna gÃ¶re film Ã¶ner. "
    "Sadece bir film Ã¶ner, kÄ±sa ve anlaÅŸÄ±lÄ±r cÃ¼mlelerle yanÄ±tla.\n\n"
    "{context}"
)

# Prompt ÅŸablonu
prompt = ChatPromptTemplate.from_messages(
    [
        ("system", system_prompt),
        ("human", "{input}")
    ]
)

# RAG zinciri
question_answer_chain = create_stuff_documents_chain(llm, prompt)
rag_chain = create_retrieval_chain(retriever, question_answer_chain)

# KullanÄ±cÄ±dan giriÅŸ al
query = st.chat_input("NasÄ±l bir film arÄ±yorsun?")

if query:
    with st.spinner("Film aranÄ±yor..."):
        try:
            response = rag_chain.invoke({"input": query})
            st.success("ğŸ¥ Film Ã–nerisi:")
            st.write(response["answer"])
        except Exception as e:
            st.error(f"âŒ Hata oluÅŸtu: {e}")